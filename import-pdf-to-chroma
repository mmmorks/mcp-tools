#!/usr/bin/env python3
"""
PDF to Chroma Importer

This script loads PDFs, splits them into chunks, creates embeddings using Amazon Bedrock,
and stores them in a Chroma vector database.
"""

import os
import argparse
import logging
from typing import Optional, List

import chromadb
from chromadb.config import Settings
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_aws import BedrockEmbeddings
from langchain_community.vectorstores import Chroma

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_pdf(pdf_path: str):
    """Load and extract text from a PDF file."""
    logger.info(f"Loading PDF from {pdf_path}")
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    logger.info(f"Loaded {len(documents)} pages from PDF")
    return documents

def split_text(documents, chunk_size: int = 1000, chunk_overlap: int = 200):
    """Split documents into chunks."""
    logger.info(f"Splitting text into chunks (size: {chunk_size}, overlap: {chunk_overlap})")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    chunks = text_splitter.split_documents(documents)
    logger.info(f"Created {len(chunks)} chunks")
    return chunks

def add_to_chroma(chunks, collection_name: str, persist_dir: str,
                 model_id: str, region_name: str, aws_profile: Optional[str] = None):
    """Create embeddings with Bedrock and store in Chroma."""
    logger.info(f"Initializing Bedrock embeddings with model {model_id} in region {region_name}")

    # Initialize Bedrock embeddings
    bedrock_kwargs = {
        "model_id": model_id,
        "region_name": region_name
    }

    if aws_profile:
        bedrock_kwargs["credentials_profile_name"] = aws_profile
        logger.info(f"Using AWS profile: {aws_profile}")

    bedrock_embeddings = BedrockEmbeddings(**bedrock_kwargs)

    # Create Chroma vector store
    logger.info(f"Creating Chroma vector store in {persist_dir}")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=bedrock_embeddings,
        collection_name=collection_name,
        persist_directory=persist_dir,
        client_settings=Settings(anonymized_telemetry=False)
    )

    # No need to call persist() as Chroma 0.4.x+ automatically persists documents
    logger.info(f"Successfully added {len(chunks)} chunks to Chroma collection '{collection_name}'")
    return vectorstore

def main():
    """Main function to parse arguments and run the script."""
    parser = argparse.ArgumentParser(
        description="Import PDFs to Chroma using Amazon Bedrock embeddings"
    )

    parser.add_argument(
        "--pdf", "-p",
        required=True,
        help="Path to the PDF file to import"
    )

    parser.add_argument(
        "--collection", "-c",
        default="pdf_collection",
        help="Name of the Chroma collection (default: pdf_collection)"
    )

    parser.add_argument(
        "--persist-dir", "-d",
        default="./chroma_db",
        help="Directory to persist the Chroma database (default: ./chroma_db)"
    )

    parser.add_argument(
        "--chunk-size",
        type=int,
        default=1000,
        help="Size of text chunks (default: 1000)"
    )

    parser.add_argument(
        "--chunk-overlap",
        type=int,
        default=200,
        help="Overlap between text chunks (default: 200)"
    )

    parser.add_argument(
        "--model-id",
        default="amazon.titan-embed-text-v1",
        choices=["amazon.titan-embed-text-v1", "cohere.embed-english-v3", "cohere.embed-multilingual-v3"],
        help="Bedrock embedding model ID (default: amazon.titan-embed-text-v1)"
    )

    parser.add_argument(
        "--region",
        default="us-east-1",
        help="AWS region for Bedrock (default: us-east-1)"
    )

    parser.add_argument(
        "--profile",
        help="AWS profile name (optional)"
    )

    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Enable verbose logging"
    )

    args = parser.parse_args()

    # Set logging level based on verbose flag
    if args.verbose:
        logger.setLevel(logging.DEBUG)

    try:
        # Check if PDF exists
        if not os.path.isfile(args.pdf):
            logger.error(f"PDF file not found: {args.pdf}")
            return 1

        # Create persist directory if it doesn't exist
        os.makedirs(args.persist_dir, exist_ok=True)

        # Process the PDF
        documents = load_pdf(args.pdf)
        chunks = split_text(documents, args.chunk_size, args.chunk_overlap)
        s = add_to_chroma(
            chunks,
            args.collection,
            args.persist_dir,
            args.model_id,
            args.region,
            args.profile
        )

        logger.info("PDF successfully imported to Chroma.")
        return 0

    except Exception as e:
        logger.error(f"Error importing PDF: {str(e)}", exc_info=True)
        return 1

if __name__ == "__main__":
    exit(main())
